{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OurOwnFunctions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Suaif/Video_descriptor/blob/master/OurOwnFunctions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rXf263b0Mgy",
        "colab_type": "text"
      },
      "source": [
        "Con el objetivo de tener nuestro código más organizado, hemos decidido crear este documento `OurOwnFunctions.ipynb.` <br>\n",
        "De esta forma podremos implementar este documento como un módulo en el documento principal `main.ipynb.`\n",
        "\n",
        "---\n",
        "\n",
        "**Lista de funciones implementadas:**\n",
        "\n",
        "* `slice_video`\n",
        "* `padding`\n",
        "* `int2str`\n",
        "* `clean_text`\n",
        "* `decode_sequence`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPl4XR9rCBNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Modulos necesarios para el correcto funcionamiento de las funciones.\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import re    as re\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from google.colab.patches         import cv2_imshow\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgJgIhNqwAa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def slice_video(video_id, pathIn, pathOut, height=240, width=240, numero_frames=6, format='.avi'):\n",
        " \n",
        "  '''\n",
        "  Dado un vídeo devuelve el `numero_frames` en la carpeta `pathOut` con \n",
        "  una `altura y anchura de (240x240)` en un formato por defecto `.avi`.\n",
        " \n",
        "  -\n",
        "  Parámetros:\n",
        "    video_id         (string)  [Id del vídeo]\n",
        "    pathIn           (string)  [Ruta de los vídeos]\n",
        "    pathOut          (string)  [Ruta guardado/salida]\n",
        "    height           (int)     [Altura del frame]\n",
        "    width            (int)     [Anchura del frame]\n",
        "    numero_frames    (int)     [Número de frames a dividir]\n",
        "    format           (string)  [Formato del vídeo. '.*' ]\n",
        "  '''\n",
        "\n",
        "  # -- Parámetros\n",
        "  vidcap     = cv2.VideoCapture(pathIn + video_id + format)\n",
        "  max_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "  num_img, count = 1, 1\n",
        "  dim = (width, height)\n",
        "\n",
        "  # Mientras no sea divisible por numero_frames restamos uno a max_frames.\n",
        "  while max_frames % numero_frames != 0:\n",
        "     max_frames -= 1\n",
        "\n",
        "  n_fps = max_frames / numero_frames\n",
        "\n",
        "  # Mientras se siga pudiendo leer y count siga siendo menor que el número máximo de frames\n",
        "  while vidcap.isOpened and count <= max_frames:\n",
        "\n",
        "    vidcap.set(cv2.CAP_PROP_FPS, 1)    \n",
        "    success,image = vidcap.read()\n",
        "    \n",
        "    # Hacemos resize de la imgen. \n",
        "    resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
        "\n",
        "    if count % n_fps == 0:\n",
        "     \n",
        "      # Si la ruta no existe, la crea.\n",
        "      if not os.path.exists(pathOut):  \n",
        "        os.mkdir(pathOut) \n",
        "     \n",
        "      # Guarda la imagen almacenada en resized en la ruta dada.\n",
        "      cv2.imwrite(pathOut + video_id + '_' + str(num_img) + \".jpg\", resized)\n",
        "      print(pathOut + video_id + '_' + str(num_img) + \".jpg\")\n",
        "      num_img += 1\n",
        "    count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZRIAM1mv6On",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def padding(Y, maxlen=0, pad='post'):\n",
        "\n",
        "  '''\n",
        "  Rellena con ceros los espacios sobrantes de un ndarray.\n",
        "  Además añade un 0 extra al final\n",
        "  -\n",
        "  Parámetros:\n",
        "    Y       (ndarray) [Descripciones]\n",
        "    maxlen  (int)     [Longitud máxima]\n",
        "    pad     (string)  [Posición del padding]\n",
        "  '''\n",
        "\n",
        "  Yt = np.asarray(Y)\n",
        "  Yt = Yt[:,np.newaxis]\n",
        "\n",
        "  if maxlen == 0:\n",
        "    \n",
        "    maxlen = max([len(Yt[i].tolist()[0]) for i in range(len(Yt))]) \n",
        "\n",
        "  Ypad = np.zeros((len(Yt), maxlen+1))\n",
        "\n",
        "  for i in range(len(Yt)):\n",
        "\n",
        "    Ypad[i,:-1] = pad_sequences(Yt[i], maxlen=maxlen,  padding=pad, value=0.0)\n",
        "\n",
        "  return Ypad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYrVx4H4v6lN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def int2str(sec, tokenizer):\n",
        "\n",
        "  '''\n",
        "  Convierte una lista de enteros a una lista de palabras.\n",
        "\n",
        "  -\n",
        "  Parámetros:\n",
        "    sec        (list)        [Lisa de enteros que se convertirán a palabras]\n",
        "    tokenizer  (dictionary)  [Contiene eliccionrio para asignar palabras a enteros]\n",
        "  '''\n",
        "\n",
        "  #Si entra una lista se convierte a array\n",
        "  if type(sec) is list:\n",
        "    sec = np.asarray(sec)\n",
        "\n",
        "  #Si solo hay una secuencia se añade otro eje\n",
        "  if len(sec.shape) == 1:\n",
        "    sec = sec[np.newaxis, :]\n",
        "\n",
        "  nsecs, nints = sec.shape\n",
        "\n",
        "  frases = np.zeros((nsecs), dtype=object) \n",
        "\n",
        "  for i in range(nsecs):\n",
        "    frases[i] = sec[i].astype(int).tolist()\n",
        "\n",
        "  return tokenizer.sequences_to_texts(frases)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB_bY1SRv7OL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "\n",
        "  '''\n",
        "  Limpia el texto pasado removiendo carácteres innecesarios.\n",
        "  \n",
        "  -\n",
        "  Parámetros:\n",
        "    text       (string) [Texto a limpiar]\n",
        "  '''\n",
        "\n",
        "  text = text.lower()\n",
        "\n",
        "  text = re.sub(r\"i'm\", \"i am\", text)\n",
        "  text = re.sub(r\"he's\", \"he is\", text)\n",
        "  text = re.sub(r\"she's\", \"she is\", text)\n",
        "  text = re.sub(r\"it's\", \"it is\", text)\n",
        "  text = re.sub(r\"that's\", \"that is\", text)\n",
        "  text = re.sub(r\"what's\", \"that is\", text)\n",
        "  text = re.sub(r\"where's\", \"where is\", text)\n",
        "  text = re.sub(r\"how's\", \"how is\", text)\n",
        "  text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "  text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "  text = re.sub(r\"\\'re\", \" are\", text)\n",
        "  text = re.sub(r\"\\'d\", \" would\", text)\n",
        "  text = re.sub(r\"\\'re\", \" are\", text)\n",
        "  text = re.sub(r\"won't\", \"will not\", text)\n",
        "  text = re.sub(r\"can't\", \"cannot\", text)\n",
        "  text = re.sub(r\"n't\", \" not\", text)\n",
        "  text = re.sub(r\"n'\", \"ng\", text)\n",
        "  text = re.sub(r\"'bout\", \"about\", text)\n",
        "  text = re.sub(r\"'til\", \"until\", text)\n",
        "  text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
        "      \n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeYXKvXBuzfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "\n",
        "  '''\n",
        "  Utiliza el encoder y el decoder para obtener la secuencia de enteros\n",
        "  correspondiente a la descripción.\n",
        "  \n",
        "  -\n",
        "  Parámetros:\n",
        "    input_seq       (array)[Secuencia de imágenes]\n",
        "  '''\n",
        "\n",
        "  \n",
        "  # Hacemos predecir al encoder y sacamos los states\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # First character of the target sequence is the start character\n",
        "  target_seq = [[2]]\n",
        "  target_seq = np.asarray(target_seq)\n",
        "  # print(target_seq.shape)\n",
        "\n",
        "  # To simplify, here we assume a batch of size 1.\n",
        "  stop_condition = False\n",
        "  decoded_sentence = []\n",
        "  while not stop_condition:\n",
        "    #aqui hacemos predecir al decoder al que le metemos el target sequence mas el state que hemos sacado antes\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "    # Sample a token\n",
        "    sampled_token_index = np.argmax(output_tokens)\n",
        "    decoded_sentence.append(sampled_token_index) #sampled_char\n",
        "    # print(sampled_token_index)\n",
        "\n",
        "    # Exit condition: either hit max length or find stop character.\n",
        "    if (len(decoded_sentence) > max_sentence_len) or (sampled_token_index==3):\n",
        "        stop_condition = True\n",
        "\n",
        "    # Update the target sequence (of length 1).    \n",
        "    target_seq = [[sampled_token_index]]\n",
        "    target_seq = np.asarray(target_seq)\n",
        "    # print(target_seq)\n",
        "\n",
        "    # Update states\n",
        "    states_value = [h, c]\n",
        "\n",
        "  return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}